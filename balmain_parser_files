import os
import requests
from bs4 import BeautifulSoup
import csv
import json
import html
from WebsiteParser import WebsiteParser
class BalmainProductParser(WebsiteParser):
    def parse_website(self, source, category):
        return super().parse_website(source, lambda soup: self.parse_product_blocks(soup, category))

    def parse_product_blocks(self, soup, category):
        parsed_data = []
        column_names = [
            'product_id', 'category', 'item_name', 'quantity', 'inventory_ats', 'price', 'discount_name',
            'pre_order', 'item_ean', 'item_master', 'item_category', 'item_category2', 'item_category3',
            'image_url', 'product_url'
        ]
        parsed_data.append(column_names)

        product_items = soup.find_all('div', class_='product-item')
        print(len(product_items))
        
        for item in product_items:
            product_info = item.find('div', class_='product')
            if product_info:
                data_analytics = product_info['data-analytics']
                analytics_data = json.loads(html.unescape(data_analytics))
                product_data = analytics_data['product']

                images = [img['src'] for img in item.find_all('img') if img.get('src')]
                product_url = item.find('a', class_='tile-body')['href']
                image_url = images[0] if images else None

                product_data_list = [
                    product_data.get('item_id', ''),
                    category,
                    product_data.get('item_name', ''),
                    product_data.get('quantity', ''),
                    product_data.get('inventory_ats', ''),
                    product_data.get('price', ''),
                    product_data.get('discount_name', ''),
                    product_data.get('pre_order', ''),
                    product_data.get('item_ean', ''),
                    product_data.get('item_master', ''),
                    product_data.get('item_category', ''),
                    product_data.get('item_category2', ''),
                    product_data.get('item_category3', ''),
                    image_url,
                    f"https://www.balmain.com{product_url}"
                ]

                parsed_data.append(product_data_list)

        return parsed_data
    
    def parse_directory(self, directory_path, output_file):
        all_data = []
        header_added = False
        total_files = len([f for f in os.listdir(directory_path) if f.endswith('.txt')])
        processed_files = 0

        print(f"Found {total_files} HTML files in the directory.")
        print("Processing files...")

        for filename in os.listdir(directory_path):
            if filename.endswith('.txt'):
                file_path = os.path.join(directory_path, filename)
                category = os.path.splitext(filename)[0]  # Use the filename as the category

                tsv_output = self.parse_website(file_path, category)

                if not header_added:
                    tsv_output[0].append('filename')  # Add the new column name for filename
                    all_data.append(tsv_output[0])  # Add the header row only once
                    header_added = True

                # Add the filename as a new column to the parsed data
                for row in tsv_output[1:]:
                    row.append(filename)
                    all_data.append(row)

                processed_files += 1
                progress = (processed_files / total_files) * 100
                print(f"Progress: {progress:.2f}% ({processed_files}/{total_files} files processed)")

        print("Writing data to TSV file...")
        self.write_to_csv(output_file, all_data)

        print(f"Parsing completed. TSV file saved as: {output_file}")

        return all_data
